{{- $models := include "llama-stack.mergeModels" . | fromJson }}
{{- $mcpServers := include "llama-stack.mergeMcpServers" . | fromJson }}
{{- $shields := list }}
{{- range $key, $model := $models }}
  {{- if and $model.enabled $model.registerShield }}
    {{- $shields = append $shields $model }}
  {{- end }}
{{- end }}
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: run-config
data:
  config.yaml: |
    version: '2'
    image_name: remote-vllm
    apis:
    - agents
    - datasetio
    - eval
    - inference
    - safety
    - scoring
    - telemetry
    - tool_runtime
    - vector_io
    providers:
      inference:
      {{- range $key, $model := $models }}
      {{- if $model.enabled }}
      - provider_id: {{ $key }}
        provider_type: remote::vllm
        config:
          url: {{ $model.url }}
          api_token: {{ $model.apiToken | default "fake" }}
          max_tokens: {{ $model.maxTokens | default 4096 }}
          tls_verify: {{ $model.tlsVerify | default false }}
      {{- end }}
      {{- end }}
      - provider_id: sentence-transformers
        provider_type: inline::sentence-transformers
        config: {}
      vector_io:
      - provider_id: pgvector
        provider_type: remote::pgvector
        config:
          host: ${env.POSTGRES_HOST:=pgvector}
          port: ${env.POSTGRES_PORT:=5432}
          db: ${env.POSTGRES_DBNAME:=rag_blueprint}
          user: ${env.POSTGRES_USER:=postgres}
          password: ${env.POSTGRES_PASSWORD:=rag_password}
      safety:
      - provider_id: llama-guard
        provider_type: inline::llama-guard
        config: {}
      agents:
      - provider_id: meta-reference
        provider_type: inline::meta-reference
        config:
          persistence_store:
            type: sqlite
            namespace: null
            db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/remote-vllm}/agents_store.db
          responses_store:
            type: sqlite
            db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/remote-vllm}/responses_store.db
      eval:
      - provider_id: meta-reference
        provider_type: inline::meta-reference
        config:
          kvstore:
            type: sqlite
            namespace: null
            db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/remote-vllm}/meta_reference_eval.db
      datasetio:
      - provider_id: huggingface
        provider_type: remote::huggingface
        config:
          kvstore:
            type: sqlite
            namespace: null
            db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/remote-vllm}/huggingface_datasetio.db
      - provider_id: localfs
        provider_type: inline::localfs
        config:
          kvstore:
            type: sqlite
            namespace: null
            db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/remote-vllm}/localfs_datasetio.db
      scoring:
      - provider_id: basic
        provider_type: inline::basic
        config: {}
      - provider_id: llm-as-judge
        provider_type: inline::llm-as-judge
        config: {}
      - provider_id: braintrust
        provider_type: inline::braintrust
        config:
          openai_api_key: ${env.OPENAI_API_KEY:=}
      telemetry:
      - provider_id: meta-reference
        provider_type: inline::meta-reference
        config:
          sinks: ${env.TELEMETRY_SINKS:=console,sqlite}
          sqlite_db_path: ${env.SQLITE_DB_PATH:=~/.llama/distributions/remote-vllm/trace_store.db}
      tool_runtime:
      - provider_id: brave-search
        provider_type: remote::brave-search
        config:
          api_key: ${env.BRAVE_SEARCH_API_KEY:=}
          max_results: 3
      - provider_id: tavily-search
        provider_type: remote::tavily-search
        config:
          api_key: ${env.TAVILY_SEARCH_API_KEY:=}
          max_results: 3
      - provider_id: rag-runtime
        provider_type: inline::rag-runtime
        config: {}
      - provider_id: model-context-protocol
        provider_type: remote::model-context-protocol
        config: {}
    metadata_store:
      type: sqlite
      db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/remote-vllm}/registry.db
    models:
    {{- range $key, $model := $models }}
    {{- if $model.enabled }}
    - metadata: {}
      model_id: {{ $model.id }}
      provider_id: {{ $key }}
      model_type: llm
    {{- end }}
    {{- end }}
    - metadata:
        embedding_dimension: 384
      model_id: all-MiniLM-L6-v2
      provider_id: sentence-transformers
      model_type: embedding
    {{- with $shields }}
    shields:
    {{- range $model := . }}
    - shield_id: {{ $model.id }}
      provider_id: llama-guard
    {{- end }}
    {{- end }}
    vector_dbs: []
    datasets: []
    scoring_fns: []
    eval_tasks: []
    tool_groups:
    - toolgroup_id: builtin::websearch
      provider_id: tavily-search
    - toolgroup_id: builtin::rag
      provider_id: rag-runtime
    {{- range $key, $server := $mcpServers }}
    - toolgroup_id: mcp::{{ $key }}
      provider_id: model-context-protocol
      mcp_endpoint:
        uri: {{ $server.uri }}
    {{- end }}
    server:
      auth:
        provider_type: "custom"
        config:
          endpoint: "http://ai-virtual-assistant:8887/validate"
        access_policy:
        - permit:
            actions: [create, update, delete]
          when: user with admin in roles
        - permit:
            actions: [create, update, delete]
            resource: session::*
        - permit:
            actions: [read]
